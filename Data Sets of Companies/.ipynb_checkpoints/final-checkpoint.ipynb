{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textract\n",
    "import os\n",
    "import datetime\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from itertools import chain\n",
    "import xml.sax\n",
    "from nltk.corpus import words,wordnet\n",
    "import gensim\n",
    "from gensim import models,similarities\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import glob\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/saphalpatro/Desktop/Data Sets of Companies\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "VERB = [\"VBD\", \"VB\", \"VBG\", \"VBN\",\"VBP\", \"VBZ\"]\n",
    "NOUN = [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\n",
    "ADVERB =[\"RB\", \"RBR\", \"RBS\"]\n",
    "ADJECTIVE = [\"JJ\", \"JJR\", \"JJS\"]\n",
    "AUXILIARY_VERB = [\"be\" , \"am\" , \"are\", \"is\", \"was\", \"being\", \"can\", \"could\", \"do\", \"did\", \"does\", \"doing\", \"have\", \"had\",\n",
    "         \"has\", \"having\", \"may\", \"might\", \"might\", \"must\", \"shall\", \"should\", \"will\", \"'ve\", \"n't\", \"were\"]\n",
    "SUBJECTS = [\"nsubj\", \"nsubjpass\", \"csubj\", \"csubjpass\", \"agent\", \"expl\"]\n",
    "OBJECTS = [\"dobj\", \"dative\", \"attr\", \"oprd\"]\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "CompanyData = pd.ExcelFile('/Users/saphalpatro/Desktop/Data Sets of Companies/Companies.xlsx')\n",
    "aspects = pd.read_excel(CompanyData,'Aspects',skiprows=1)\n",
    "namesOfCompanies = list(aspects['Companies'])\n",
    "namesOfCompanies = [str(x) for x in namesOfCompanies]\n",
    "# print(namesOfCompanies)\n",
    "words = [str(x) for x in list(aspects.columns[1:])]\n",
    "# print(words)\n",
    "\n",
    "#List of Words\n",
    "risk = pd.DataFrame(['risk','danger','exposure','hazard','liability','opportunity','peril','possibility','prospect','uncertainity','accident','contingency','flyer','fortuity','fortune','gamble','header','jeopardy','luck','openness','plunge','speculation','stab','venture','wager','exposedness','liable'])\n",
    "investment = pd.DataFrame(['investment','asset','contribution','expenditure','investment','expense','finance','financing','grant','loan','money','property','purchase','stake','transaction','venture','advance','ante','backing','bail','endowment','flutter','hunch','inside','interests','investing','piece','plunge','spec','speculation','stab','smart money','vested interests'])\n",
    "entrepreneurship = pd.DataFrame(['entrepreneurship','administrator','contractor','executive','manager','producer','backer','businessperson','businessman','founder','industrialist','organiser','promoter','undertaker','enterprise','entrepreneurialism','entrepreneurism','capital','capitalism','industrailism'])\n",
    "venture = pd.DataFrame(['venture','deal','endeavor','enterprise','investment','project','undertaking','adventure','baby','chance','essay','exploit','feat','hazard','header','peril','jeopardy','peril','proposition','pursuit','setup','shot','speculation','stab','stake','test','thing','trial','wager','product'])\n",
    "novel = pd.DataFrame(['novel','different','innovative','odd','offbeat','colourful','peculiar','strange','unique','unusual','contemporary','avant-grade','now','recent','singular','cutting-edge','atypical','breaking-new','ground','farcry','fresh','funky','justout','modernistic','neoteric','new-fashioned','newfangled','rare','uncommon','unfamiliar'])\n",
    "innovation = pd.DataFrame(['innovation','modernisation','addition','alteration','contraption','departure','deviation','introduction','modernism','modification','mutation','newness','notion','permutation','shift','variation','vicissitude','wrinkle','cutting-edge','last word','latest thing','leading edge'])\n",
    "patent = pd.DataFrame(['patent','charter','concession','license','privilege','protection','control','franchise','limitation'])\n",
    "divestiture = pd.DataFrame(['divestiture','disinvestment','divestment','dispossession','privation','divesture'])\n",
    "acquire = pd.DataFrame(['acquire','achieve','amass','bring-in','buy','collect','earn','gain','get','have','pickup','promote','win','access','annex','attain','catch','cop','corral','gather','grab','hustle','land','procure','snag','secure','wangle','get hands on','get hold of','possess','possession'])\n",
    "diversify = pd.DataFrame(['diversify','expand','transform','alter','assort','change','mix','modify','varigate','vary'])\n",
    "failure = pd.DataFrame(['failure','bankruptcy','breakdown','collapse','decline','defeat','deficiency','deterioration','failing','loss','misstep','abortion','bomb','botch','bungle','bust','checkmate','decay','deficit','downfall','fiasco','flop','frustration','implosion','inadequacy','lemon','loser','mess','misadventure','miscarriage','nonperformance','overthrow','rout','rupture','stalemate','stoppage','turkey','washout','wreck'])\n",
    "success = pd.DataFrame(['success','accomplisment','achievement','advance','benefit','boom','fame','gain','happiness','profit','progress','prosperity','realisation','triumph','victory','win','arrival','ascendency','attainment','clover','consummation','eminence','fortune','fruition','hit','killing','laughter','maturation','reward','savvy','sensation','snap','strike','successfulness','walkaway','walkover'])\n",
    "synonyms = pd.concat([risk,investment,entrepreneurship,venture,novel,innovation,patent,divestiture,acquire,diversify,failure,success],ignore_index = True,axis = 1)\n",
    "synonyms.columns = words\n",
    "\n",
    "filename = 'Text of all Companies.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstring(list):\n",
    "    mes = ''\n",
    "    for i in range(len(list)):\n",
    "        mes+=(str(list[i])+' ')\n",
    "    return mes\n",
    "\n",
    "def iscomp(list,comp):\n",
    "    for i in range(len(list)):\n",
    "        if list[i] in comp:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def listtoString(list):\n",
    "    string = ''\n",
    "    for i in range(len(list)):\n",
    "        if str(type(list[i])) == \"<type 'NoneType'>\" or len(list[i]) <= 0:\n",
    "            continue\n",
    "        elif len(list[i])>1 or str(type(list[i])) == \"<type 'list'>\":\n",
    "            for j in range(len(list[i])):\n",
    "                string+= (str(list[i][j]) + ' ')\n",
    "        else:\n",
    "            string+=(str(list[i]) + ' ')\n",
    "    return string\n",
    "\n",
    "def getWords(list):\n",
    "    words = []\n",
    "    for i in range(len(list)):\n",
    "        words.append(list[i][0])\n",
    "    return words\n",
    "\n",
    "def getFiles(dir):\n",
    "    os.chdir(dir)\n",
    "    fn = []\n",
    "    for file in glob.glob(\"*.pdf\"):\n",
    "        fn.append(file)\n",
    "    return fn\n",
    "\n",
    "def extract_txt(file):\n",
    "    try:\n",
    "        txt = textract.process(file)\n",
    "    except UnicodeDecodeError:\n",
    "        print 'File', file, 'cannot be extracted! - skipped'\n",
    "        txt = ''\n",
    "    return txt\n",
    "\n",
    "def getDir(CompanyName):\n",
    "    CompanyName = '/'+ str(CompanyName)\n",
    "    return '/Users/saphalpatro/Desktop/Data Sets of Companies'+ CompanyName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2015.pdf cannot be extracted! - skipped\n",
      "20 Microns\n",
      "Aditya Birla Money\n",
      "Colgate\n",
      "Dabur\n",
      "Federal Bank\n",
      "Kotak Mahindra Bank\n",
      "Mahindra and Mahindra\n",
      "United Breweries\n",
      "TCS\n",
      "Hindustan Unilever\n"
     ]
    }
   ],
   "source": [
    "filename = 'Text of all Companies.pickle'\n",
    "i = 0\n",
    "text = []\n",
    "for company in namesOfCompanies:\n",
    "    dir = getDir(company)\n",
    "    os.chdir(dir)\n",
    "    os.chdir('Management Discussion and Analysis')\n",
    "    files = getFiles(os.getcwd())\n",
    "    string = ''\n",
    "    for f in files:\n",
    "        string = string + extract_txt(f)\n",
    "    text.append([string,company])\n",
    "    print(text[i][1])\n",
    "    i+=1\n",
    "\n",
    "os.chdir(current_dir)\n",
    "pickle_out = open(filename,\"wb\")\n",
    "pickle.dump(text, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# pickle_in = open(filename,\"rb\")\n",
    "# text = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Microns\n",
      "Aditya Birla Money\n",
      "Colgate\n",
      "Dabur\n",
      "Federal Bank\n",
      "Kotak Mahindra Bank\n",
      "Mahindra and Mahindra\n",
      "United Breweries\n",
      "TCS\n",
      "Hindustan Unilever\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(filename,\"rb\")\n",
    "text = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
